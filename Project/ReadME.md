## AI Final Project Submission

### Class ID: 108168

**How we approached the Task**
By making and training to our models. We did create 6 model to check the behavior of Data Response and got different responses from them among those responses we selected the best response we got which was much accurate as compared to others and more faster in generating result.

**Which models we selected and why**
We Selected Adaptive Boosting and Decision Tree These two model were more efficient then other mostly all model generated the same result. but some of them took alot of time while in test run how ever these two model generated result more accurate yet more faster then others However Decision Tree display response even more faster than Adaptive Boosting.

**What were the performances of each model on local test data.**

##### Model 1 -> Logistic Regression
AdaBoost also called Adaptive Boosting is a technique in Machine Learning used as an Ensemble Method. The most common algorithm used with AdaBoost is decision trees with one level that means with Decision trees with only 1 split. These trees are also called Decision Stumps.

##### Model 2 -> Random Forest
A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. The sub-sample size is controlled with the max_samples parameter if bootstrap=True (default), otherwise the whole dataset is used to build each tree.

##### Model 3 -> Multinomial Naive Bayes
In probability theory, the multinomial distribution is a generalization of the binomial distribution. For example, it models the probability of counts for each side of a k-sided die rolled n times. For n independent trials each of which leads to a success for exactly one of k categories, with each category having a given fixed success probability, the multinomial distribution gives the probability of any particular combination of numbers of successes for the various categories.

##### Model 4 -> Decision Tree Classifier
Decision Tree is a Supervised Machine Learning Algorithm that uses a set of rules to make decisions, similarly to how humans make decisions.
One way to think of a Machine Learning classification algorithm is that it is built to make decisions.
You usually say the model predicts the class of the new, never-seen-before input but, behind the scenes, the algorithm has to decide which class to assign.

##### Model 5 -> KNN - K Nearest Neighbors
A supervised machine learning algorithm (as opposed to an unsupervised machine learning algorithm) is one that relies on labeled input data to learn a function that produces an appropriate output when given new unlabeled data.
Imagine a computer is a child, we are its supervisor (e.g. parent, guardian, or teacher), and we want the child (computer) to learn what a pig looks like. We will show the child several different pictures, some of which are pigs and the rest could be pictures of anything (cats, dogs, etc).

##### Model 6 -> Adaptive Boostings
AdaBoost also called Adaptive Boosting is a technique in Machine Learning used as an Ensemble Method. The most common algorithm used with AdaBoost is decision trees with one level that means with Decision trees with only 1 split. These trees are also called Decision Stumps.

**Problem we face:**

> This task is new to us thats why we done many mistake while searching solution to a problem. Because of wrong searching we got stuck on some points for a long time.

**References we used**
We took referece and guidance from website of GeeksforGeeks, Online Blog and Youtube Videos.

**Score:**
![Kaggle Score](/Project/img.png)
